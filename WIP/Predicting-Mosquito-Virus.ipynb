{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# West Nile Mosquito Virus kaggle competition prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team of 3\n",
    "     Development by Nasrudin\n",
    "     Documentation by Nasrudin\n",
    "     Visualizations by Nasrudin\n",
    "#### This was supposed to be a team project in General Assembly's Data Science Immersive Course     \n",
    "#### I ended up doing the project by myself.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective and Targets\n",
    "    Clear Documentation\n",
    "    AUC Score of at least 0.95\n",
    "    CleanCode\n",
    "#### Metrics\n",
    "    Accuracy\n",
    "    AUC\n",
    "     \n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Information\n",
    "West Nile virus is most commonly spread to humans through infected mosquitos. Around 20% of people who become infected with the virus develop symptoms ranging from a persistent fever, to serious neurological illnesses that can result in death.\n",
    "\n",
    "\n",
    "\n",
    "In 2002, the first human cases of West Nile virus were reported in Chicago. By 2004 the City of Chicago and the Chicago Department of Public Health (CDPH) had established a comprehensive surveillance and control program that is still in effect today.\n",
    "\n",
    "Every week from late spring through the fall, mosquitos in traps across the city are tested for the virus. The results of these tests influence when and where the city will spray airborne pesticides to control adult mosquito populations.\n",
    "\n",
    "Given weather, location, testing, and spraying data, this competition asks you to predict when and where different species of mosquitos will test positive for West Nile virus. A more accurate method of predicting outbreaks of West Nile virus in mosquitos will help the City of Chicago and CPHD more efficiently and effectively allocate resources towards preventing transmission of this potentially deadly virus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Jupyter Notebook is in Python 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this project, I'll be exploring and using:\n",
    "## Models using these packages\n",
    "### I will also attempt to stack and/or ensemble some models\n",
    "    Tensorflow\n",
    "    SkLearn\n",
    "    XGBoost\n",
    "### Models\n",
    "    Logisticic Regrssion\n",
    "    RandomForests\n",
    "    Deep Neural Networks\n",
    "    XGBoost Models\n",
    "\n",
    "## Validation and refining, tuning hyperparameters\n",
    "    K-means Cross Validation\n",
    "    Cross Validation w/ hold out\n",
    "    GridSearch\n",
    "    Feature Selection\n",
    "    Model Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import basic stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble, preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('assets/kaggle/train.csv')\n",
    "test = pd.read_csv('assets/kaggle/test.csv')\n",
    "sample = pd.read_csv('assets/kaggle/sampleSubmission.csv')\n",
    "weather = pd.read_csv('assets/kaggle/weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train.WnvPresent.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using codesum\n",
    "weather = weather.drop('CodeSum', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split station 1 and 2 and join horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_stn1 = weather[weather['Station']==1]\n",
    "weather_stn2 = weather[weather['Station']==2]\n",
    "weather_stn1 = weather_stn1.drop('Station', axis=1)\n",
    "weather_stn2 = weather_stn2.drop('Station', axis=1)\n",
    "weather = weather_stn1.merge(weather_stn2, on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace some missing values and T with -1, based on the data description provided in pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.replace('M', -1)\n",
    "weather = weather.replace('-', -1)\n",
    "weather = weather.replace('T', -1)\n",
    "weather = weather.replace(' T', -1)\n",
    "weather = weather.replace('  T', -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to extract month and day from dataset\n",
    "#### You can also use parse_dates of Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_month(x):\n",
    "    return x.split('-')[1]\n",
    "\n",
    "def create_day(x):\n",
    "    return x.split('-')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train.Date.apply(create_month)\n",
    "train['day'] = train.Date.apply(create_day)\n",
    "test['month'] = test.Date.apply(create_month)\n",
    "test['day'] = test.Date.apply(create_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the Latitude/longtitude columns as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Lat_int'] = train.Latitude.apply(int)\n",
    "train['Long_int'] = train.Longitude.apply(int)\n",
    "test['Lat_int'] = test.Latitude.apply(int)\n",
    "test['Long_int'] = test.Longitude.apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the address columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Address', 'AddressNumberAndStreet','WnvPresent', 'NumMosquitos'], axis = 1)\n",
    "test = test.drop(['Id', 'Address', 'AddressNumberAndStreet'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge with weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(weather, on='Date')\n",
    "test = test.merge(weather, on='Date')\n",
    "train = train.drop(['Date'], axis = 1)\n",
    "test = test.drop(['Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Categorical Data to numbers using LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = preprocessing.LabelEncoder()\n",
    "lbl.fit(list(train['Species'].values) + list(test['Species'].values))\n",
    "train['Species'] = lbl.transform(train['Species'].values)\n",
    "test['Species'] = lbl.transform(test['Species'].values)\n",
    "\n",
    "lbl.fit(list(train['Street'].values) + list(test['Street'].values))\n",
    "train['Street'] = lbl.transform(train['Street'].values)\n",
    "test['Street'] = lbl.transform(test['Street'].values)\n",
    "\n",
    "lbl.fit(list(train['Trap'].values) + list(test['Trap'].values))\n",
    "train['Trap'] = lbl.transform(train['Trap'].values)\n",
    "test['Trap'] = lbl.transform(test['Trap'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns with -1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[:,(train != -1).any(axis=0)]\n",
    "test = test.loc[:,(test != -1).any(axis=0)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Validation\n",
    "Lets create some metric functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def measure_accuracy(model,data,labels):\n",
    "    predictions = model.predict(data)\n",
    "    return accuracy_score(labels,predictions,normalize=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=1.0,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_jobs=-1, n_estimators=1000, min_samples_split=1.0)\n",
    "clf.fit(train, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the predictions and submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(test)[:,1]\n",
    "sample['WnvPresent'] = predictions\n",
    "sample.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05241719,  0.05241719,  0.05241719, ...,  0.05241719,\n",
       "        0.05241719,  0.05241719])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
